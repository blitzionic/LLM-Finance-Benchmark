{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai \n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "notebook_dir = os.getcwd()  # Get current working directory\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"../..\"))\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: gpt-4o-mini, B-1, runs through all agent configuration\n",
    "def run_pipeline(config: str, dataset_path: str, output_dir: str, model: str = \"llama-2-70b-chat\", **kwargs):\n",
    "    \"\"\"\n",
    "    Run the pipeline on a dataset with the specified configuration.\n",
    "\n",
    "    Args:\n",
    "        config: Pipeline configuration (B-0 to B-3)\n",
    "        dataset_path: Path to the dataset file\n",
    "        output_dir: Directory to save results\n",
    "        model: Model to use\n",
    "        **kwargs: Additional provider-specific arguments\n",
    "    \"\"\"\n",
    "    # load env variables \n",
    "    load_dotenv()\n",
    "    \n",
    "    # Ensure dataset file exists\n",
    "    if not os.path.exists(dataset_path):\n",
    "        raise FileNotFoundError(f\"Dataset file not found: {dataset_path}\")\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # set up RAG if needed\n",
    "    query_engine = None\n",
    "    if config in [\"B-1\", \"B-3\"]:\n",
    "        query_engine = get_query_engine() \n",
    "    \n",
    "    # Remove provider from kwargs since it's already in the config\n",
    "    provider = kwargs.pop(\"provider\")\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        config=config,\n",
    "        provider=provider,\n",
    "        model=model,\n",
    "        query_engine=query_engine,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    # load current dataset \n",
    "    df = pd.read_csv(dataset_path)\n",
    "    results = []\n",
    "    \n",
    "    # Process each question\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {config}\"):\n",
    "        # Format question with choices in a clear, structured format\n",
    "        question_text = f\"\"\"\n",
    "        {row['question']}\n",
    "        A) {row['A']}\n",
    "        B) {row['B']}\n",
    "        C) {row['C']}\n",
    "        D) {row['D']}\n",
    "        \"\"\"\n",
    "        result = pipeline.process(question_text)\n",
    "        result[\"ground_truth\"] = row[\"answer\"]\n",
    "        results.append(result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    output_path = os.path.join(output_dir, f\"{config}_results.csv\")\n",
    "    \n",
    "    # Save results, overwriting if file exists\n",
    "    results_df.columns = [f\"{col}_{model}_{config}\" for col in results_df.columns]\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Results of model {model} and config {config} saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_provider_config(provider: str, model: str = None) -> dict:\n",
    "    \"\"\"\n",
    "    Get the configuration for the specified provider.\n",
    "    \n",
    "    Args:\n",
    "        provider: One of \"openai\", \"runpod\", \"anthropic\", \"google\"\n",
    "        model: Optional model name to override the default\n",
    "        \n",
    "    Returns:\n",
    "        dict: Provider configuration\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    \n",
    "    # Default models for each provider\n",
    "    default_models = {\n",
    "        \"openai\": \"gpt-4o-mini\",\n",
    "        \"runpod\": \"llama-2-70b-chat\",\n",
    "        \"anthropic\": \"claude-3-opus-20240229\",\n",
    "        \"google\": \"gemini-pro\"\n",
    "    }\n",
    "    \n",
    "    # Available models for each provider\n",
    "    available_models = {\n",
    "        \"openai\": [\"gpt-4o-mini\", \"gpt-4-turbo\", \"gpt-3.5-turbo\"],\n",
    "        \"runpod\": [\"llama-2-70b-chat\", \"llama-2-13b-chat\", \"llama-2-7b-chat\"],\n",
    "        \"anthropic\": [\"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\"],\n",
    "        \"google\": [\"gemini-pro\", \"gemini-pro-vision\"]\n",
    "    }\n",
    "    \n",
    "    if provider not in available_models:\n",
    "        raise ValueError(f\"Unknown provider: {provider}\")\n",
    "        \n",
    "    # Use provided model or default\n",
    "    model = model or default_models[provider]\n",
    "    if model not in available_models[provider]:\n",
    "        raise ValueError(f\"Model {model} not available for provider {provider}. Available models: {available_models[provider]}\")\n",
    "    \n",
    "    config = {\n",
    "        \"provider\": provider,\n",
    "        \"model\": model\n",
    "    }\n",
    "    \n",
    "    # Add provider-specific configurations\n",
    "    if provider == \"openai\":\n",
    "        config[\"api_key\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "    elif provider == \"runpod\":\n",
    "        config[\"endpoint\"] = os.getenv(\"RUNPOD_ENDPOINT\")\n",
    "        config[\"api_key\"] = os.getenv(\"RUNPOD_API_KEY\")\n",
    "    elif provider == \"anthropic\":\n",
    "        config[\"api_key\"] = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    elif provider == \"google\":\n",
    "        config[\"api_key\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        \n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run the pipeline for all configurations and datasets\"\"\"\n",
    "    # example: python run_pipeline.py --provider openai --model gpt-4o-mini --config B-0\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Run the pipeline with different LLM providers\")\n",
    "    parser.add_argument(\n",
    "        \"--provider\",\n",
    "        type=str,\n",
    "        choices=[\"openai\", \"runpod\", \"anthropic\", \"google\"],\n",
    "        default=\"runpod\",\n",
    "        help=\"LLM provider to use\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        type=str,\n",
    "        help=\"Specific model to use with the provider\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--config\",\n",
    "        type=str,\n",
    "        choices=[\"B-0\", \"B-1\", \"B-2\", \"B-3\", \"all\"],\n",
    "        default=\"all\",\n",
    "        help=\"Which configuration to run (B-0 to B-3, or 'all' for all configurations)\"\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Get provider configuration\n",
    "    provider_config = get_provider_config(args.provider, args.model)\n",
    "    \n",
    "    # Ask user about dataset selection\n",
    "    print(\"\\nDataset Selection:\")\n",
    "    print(\"1. Run on a specific file\")\n",
    "    print(\"2. Run on all CSV files in question_sheets\")\n",
    "    choice = input(\"Enter your choice (1 or 2): \").strip()\n",
    "    \n",
    "    # Get path relative to root directory\n",
    "    root_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "    datasheets_directory = os.path.join(root_dir, \"data\", \"question_sheets\")\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        csv_files = glob.glob(os.path.join(datasheets_directory, \"*.csv\"))\n",
    "        print(\"\\nAvailable datasets:\")\n",
    "        for i, file in enumerate(csv_files, 1):\n",
    "            print(f\"{i}. {os.path.basename(file)}\")\n",
    "        \n",
    "        file_choice = input(\"\\nEnter the number of the file you want to use: \").strip()\n",
    "        try:\n",
    "            file_idx = int(file_choice) - 1\n",
    "            if 0 <= file_idx < len(csv_files):\n",
    "                dataset_files = [csv_files[file_idx]]\n",
    "            else:\n",
    "                print(\"Invalid file number. Exiting.\")\n",
    "                return\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Exiting.\")\n",
    "            return\n",
    "            \n",
    "    elif choice == \"2\":\n",
    "        # Get all CSV files\n",
    "        dataset_files = glob.glob(os.path.join(datasheets_directory, \"*.csv\"))\n",
    "        if not dataset_files:\n",
    "            print(\"No CSV files found in data/question_sheets/\")\n",
    "            return\n",
    "    else:\n",
    "        print(\"Invalid choice. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Determine which configs to run\n",
    "    if args.config == \"all\":\n",
    "        configs = [\"B-0\", \"B-1\", \"B-2\", \"B-3\"]\n",
    "    else:\n",
    "        configs = [args.config]\n",
    "    \n",
    "    for dataset_file in dataset_files:\n",
    "        dataset_name = os.path.splitext(os.path.basename(dataset_file))[0]\n",
    "        output_dir = os.path.join(root_dir, \"data\", \"results\", dataset_name, args.provider, provider_config['model'])\n",
    "        \n",
    "        print(f\"\\nProcessing dataset: {dataset_name}\")\n",
    "        print(f\"Using provider: {args.provider}\")\n",
    "        print(f\"Using model: {provider_config['model']}\")\n",
    "        \n",
    "        for config in configs:\n",
    "            print(f\"\\nRunning {config} with {args.provider}\")\n",
    "            try:\n",
    "                run_pipeline(\n",
    "                    config=config,\n",
    "                    dataset_path=dataset_file,\n",
    "                    output_dir=output_dir,\n",
    "                    **provider_config\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error running {config}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--provider {openai,runpod,anthropic,google}]\n",
      "                             [--model MODEL] [--config {B-0,B-1,B-2,B-3,all}]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\andyz\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3f9cb4eafc0845286036207689589c92b195e41a4.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
