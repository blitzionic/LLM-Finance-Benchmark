{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import faiss\n",
    "# import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") \n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load financial documents for RAG \n",
    "from llama_index.core import GPTVectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage\n",
    "from llama_index.embeddings import HuggingFaceEmbedding\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "financial_docs_directory = os.path.join(\"../../data/financial_docs\")\n",
    "documents = SimpleDirectoryReader(financial_docs_directory).load_data() \n",
    "print(f\"Loaded {len(documents)} documents from {financial_docs_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vector store index\n",
    "index = GPTVectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "storage_context = index.storage_context\n",
    "storage_context.persist()\n",
    "print(f\"Vector store index has been built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from storage \n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "index = load_index_from_storage(storage_context)\n",
    "# set query engine \n",
    "query_engine = index.as_query_engine(llm = \"gpt-4o-mini\", similarity_top_k = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"Explain return on equity\")\n",
    "\n",
    "# Print the final LLM-generated response\n",
    "print(\"🔍 LLM Response:\\n\", response.response)\n",
    "print(f\"Input tokens: {response.metadata['input_tokens']}\")\n",
    "print(f\"Output tokens: {response.metadata['output_tokens']}\")\n",
    "print(response.metadata['usage'])  # If available\n",
    "\n",
    "\n",
    "# Print the retrieved context chunks (aka source nodes)\n",
    "print(\"\\n📚 Retrieved Chunks:\")\n",
    "for i, node in enumerate(response.source_nodes):\n",
    "    print(f\"\\n--- Chunk #{i+1} ---\")\n",
    "    print(node.node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_path = r\"..\\..\\agents\"\n",
    "if agents_path not in sys.path:\n",
    "    sys.path.append(agents_path)\n",
    "utils_path = r\"..\\..\\utils\"\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_agent import Agent\n",
    "from initial_generator import InitialGeneratorAgent\n",
    "from reviewer import ReviewerAgent\n",
    "from challenger import ChallengerAgent\n",
    "from refiner import RefinerAgent\n",
    "# from decider import DeciderAgent\n",
    "\n",
    "from utils import load_dataset, save_results, calculate_score, load_config, get_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasheets_directory = r\"..\\..\\data\\question_sheets\"\n",
    "datasheets_files = glob.glob(os.path.join(datasheets_directory, \"*.csv\"))\n",
    "# print(f\"Found {len(datasheets_files)} CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''''\n",
    "1. Initial Generation\n",
    "'''''\n",
    "\n",
    "initialAgent = InitialGeneratorAgent(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "initial_generator_agent_results = [] \n",
    "\n",
    "config_directory = os.path.join(\"..\\..\\config\")\n",
    "topic_roles_path = os.path.join(config_directory, \"topic_roles.json\")\n",
    "results_directory = os.path.join(\"..\\..\\data\", \"results\")\n",
    "os.makedirs(results_directory, exist_ok=True)\n",
    "\n",
    "for sheet in tqdm(datasheets_files, desc = \"Processing CSV files...\"):\n",
    "  print(f\"Processing file: {sheet}\")\n",
    "\n",
    "  base_name = os.path.basename(sheet)           \n",
    "  sheet_name, ext = os.path.splitext(base_name) \n",
    "\n",
    "  ReviewerAgent = ReviewerAgent(topic = sheet_name, model = \"gpt-4o-mini\", topic_roles_json=topic_roles_path)\n",
    "  \n",
    "\n",
    "  dataset = load_dataset(sheet)\n",
    "  \n",
    "  initial_guesses = []\n",
    "  reviewer_guesses = [] \n",
    "  for index, row in tqdm(dataset.iterrows(), total=len(dataset), desc=\"Processing rows...\", leave=False):\n",
    "    question = (\n",
    "      f\"{row['question']}\\n\"\n",
    "      f\"A: {row['A']}\\n\"\n",
    "      f\"B: {row['B']}\\n\"\n",
    "      f\"C: {row['C']}\\n\"\n",
    "      f\"D: {row['D']}\\n\"\n",
    "    )\n",
    "\n",
    "    print(question)\n",
    "\n",
    "    initial_response = initialAgent.process(question)\n",
    "    print(f\"initial response: {initial_response}\")\n",
    "    initial_guesses.append(initial_response)\n",
    "    # combines the 'answer' and 'reasoning' in initial response dictionary\n",
    "    # combined_initial_guess = f\"{initial_response.get('answer')}\\nReasoning: {initial_response.get('reasoning')}\"\n",
    "    '''''\n",
    "    Question -> Initial: {answer, reasoning} -> Reviewer: {answer, reasoning} -> Challenger {answer, reasoning} -> Refiner {answer, reasoning} -> Decider {answer, reasoning}\n",
    "    '''''\n",
    "    print(f\"initial guess: {initial_response}\")\n",
    "    reviewer_response = ReviewerAgent.process(question, initial_response)\n",
    "    reviewer_guesses.append(reviewer_response)\n",
    "    print(f\"Reveiewer response: {reviewer_response}\")\n",
    "\n",
    "    ChallengerAgent = ChallengerAgent(topic=\"Finance\", model=\"gpt-4o-mini\", query_engine=query_engine, topic_roles_json=topic_roles_path) \n",
    "    challenger_response = ChallengerAgent.process()\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "  dataset[\"initial_guess\"] = initial_guesses\n",
    "  dataset[\"reveiwer_guess\"] = reviewer_guesses\n",
    "  # data[\"decider_guess\"] = decider_guess\n",
    "\n",
    "\n",
    "  \n",
    "  # check correctness \n",
    "  initial_accuracy = calculate_score(dataset, answer_column=\"answer\", guess_column=\"inital_guess\")\n",
    "  print(f\"Accuracy for {os.path.basename(sheet)}: {initial_accuracy:.2f}%\")\n",
    "  \n",
    "  reveiwer_accuracy = calculate_score(dataset, answer_column=\"answer\", guess_column=\"reviewer_guess\")\n",
    "  print(f\"Accuracy for {os.path.basename(sheet)}: {initial_accuracy:.2f}%\")\n",
    "\n",
    "  output_filename = f\"{sheet_name}_gpt-4o-mini{ext}\"\n",
    "\n",
    "  output_file = os.path.join(results_directory, output_filename)\n",
    "  save_results(dataset, output_file)\n",
    "  \n",
    "  initial_generator_agent_results.append(dataset)\n",
    "  \n",
    "  break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
